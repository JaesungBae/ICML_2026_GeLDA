@inproceedings{emobox,
  title     = {{EmoBox}: Multilingual Multi-corpus Speech Emotion Recognition Toolkit and Benchmark},
  author    = {Ziyang Ma and Mingjie Chen and Hezhao Zhang and Zhisheng Zheng and Wenxi Chen and Xiquan Li and Jiaxin Ye and Xie Chen and Thomas Hain},
  year      = {2024},
  booktitle = {Interspeech 2024},
  pages     = {1580--1584},
  doi       = {10.21437/Interspeech.2024-788},
  issn      = {2958-1796},
}

@inproceedings{CaFE,
author = {Gournay, Philippe and Lahaie, Olivier and Lefebvre, Roch},
title = {A {Canadian French} emotional speech dataset},
year = {2018},
isbn = {9781450351928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3204949.3208121},
doi = {10.1145/3204949.3208121},
abstract = {Until recently, there was no emotional speech dataset available in Canadian French. This was a limiting factor for research activities not only in Canada, but also elsewhere. This paper introduces the newly released Canadian French Emotional (CaFE) speech dataset and gives details about its design and content. This dataset contains six different sentences, pronounced by six male and six female actors, in six basic emotions plus one neutral emotion. The six basic emotions are acted in two different intensities. The audio is digitally recorded at high-resolution (192 kHz sampling rate, 24 bits per sample). This new dataset is freely available under a Creative Commons license (CC BY-NC-SA 4.0).},
booktitle = {Proceedings of the 9th ACM Multimedia Systems Conference},
pages = {399–402},
numpages = {4},
keywords = {canadian french, digital recording, emotional speech, speech dataset},
location = {Amsterdam, Netherlands},
series = {MMSys '18}
}

@inproceedings{EmoDB,
  title     = {A database of {German} emotional speech},
  author    = {Felix Burkhardt and A. Paeschke and M. Rolfes and Walter F. Sendlmeier and Benjamin Weiss},
  year      = {2005},
  booktitle = {Interspeech 2005},
  pages     = {1517--1520},
  doi       = {10.21437/Interspeech.2005-446},
  issn      = {2958-1796},
}

@inproceedings{italian1,
    author = "F. Catania",
    title = "Speech emotion recognition in {Italian} using {Wav2Vec}
2",
    booktitle = "Authorea Preprints",
    year = 2023
}
@inproceedings{subesco,
    author = {S. Sultana and M. S. Rahman and M. R. Selim and M. Z. Iqbal},
    title = {{SUST} {B}angla emotional speech corpus ({SUBESCO}): An audio-only emotional speech corpus for {Bangla}},
    booktitle = {Proc. PloS One},
    year = 2021
}

@inproceedings{samsemo,
  title     = {{SAMSEMO}: New dataset for multilingual and multimodal emotion recognition},
  author    = {Pawel Bujnowski and Bartlomiej Kuzma and Bartlomiej Paziewski and Jacek Rutkowski and Joanna Marhula and Zuzanna Bordzicka and Piotr Andruszkiewicz},
  year      = {2024},
  booktitle = {Interspeech 2024},
  pages     = {2925--2929},
  doi       = {10.21437/Interspeech.2024-212},
  issn      = {2958-1796},
}

@article{kesdy18,
  author       = {Kyoung Ju Noh and
                  Chi Yoon Jeong and
                  Jiyoun Lim and
                  Seungeun Chung and
                  Gague Kim and
                  Jeong{-}Mook Lim and
                  Hyuntae Jeong},
  title        = {Multi-Path and Group-Loss-Based Network for Speech Emotion Recognition
                  in Multi-Domain Datasets},
  journal      = {Sensors},
  volume       = {21},
  number       = {5},
  pages        = {1579},
  year         = {2021},
  url          = {https://doi.org/10.3390/s21051579},
  doi          = {10.3390/S21051579},
  timestamp    = {Sat, 30 Sep 2023 10:25:57 +0200},
  biburl       = {https://dblp.org/rec/journals/sensors/NohJLCKLJ21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ravdess,
    author = {S. R. Livingstone and F. A. Russo},
    title = {The Ryerson audio-visual
database of emotional speech and song (RAVDESS): A dynamic,
multimodal set of facial and vocal expressions in North American
English},
    booktitle = {S. R. Livingstone and F. A. Russo},
    year = 2018
}
S. R. Livingstone and F. A. Russo, “The Ryerson audio-visual
database of emotional speech and song (RAVDESS): A dynamic,
multimodal set of facial and vocal expressions in North American
English,” in Proc. PloS One, 2018.

@inproceedings{esd,
  author       = {Kun Zhou and
                  Berrak Sisman and
                  Rui Liu and
                  Haizhou Li},
  title        = {Seen and Unseen Emotional Style Transfer for Voice Conversion with
                  {A} New Emotional Speech Dataset},
  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing,
                  {ICASSP} 2021, Toronto, ON, Canada, June 6-11, 2021},
  pages        = {920--924},
  publisher    = {{IEEE}},
  year         = {2021},
  url          = {https://doi.org/10.1109/ICASSP39728.2021.9413391},
  doi          = {10.1109/ICASSP39728.2021.9413391},
  timestamp    = {Sat, 06 Jan 2024 16:57:38 +0100},
  biburl       = {https://dblp.org/rec/conf/icassp/ZhouS0021.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{seamless,
      title={{SeamlessM4T}: Massively Multilingual \& Multimodal Machine Translation}, 
      author={Seamless Communication and Loïc Barrault and Yu-An Chung and Mariano Cora Meglioli and David Dale and Ning Dong and Paul-Ambroise Duquenne and Hady Elsahar and Hongyu Gong and Kevin Heffernan and John Hoffman and Christopher Klaiber and Pengwei Li and Daniel Licht and Jean Maillard and Alice Rakotoarison and Kaushik Ram Sadagopan and Guillaume Wenzek and Ethan Ye and Bapi Akula and Peng-Jen Chen and Naji El Hachem and Brian Ellis and Gabriel Mejia Gonzalez and Justin Haaheim and Prangthip Hansanti and Russ Howes and Bernie Huang and Min-Jae Hwang and Hirofumi Inaguma and Somya Jain and Elahe Kalbassi and Amanda Kallet and Ilia Kulikov and Janice Lam and Daniel Li and Xutai Ma and Ruslan Mavlyutov and Benjamin Peloquin and Mohamed Ramadan and Abinesh Ramakrishnan and Anna Sun and Kevin Tran and Tuan Tran and Igor Tufanov and Vish Vogeti and Carleigh Wood and Yilin Yang and Bokai Yu and Pierre Andrews and Can Balioglu and Marta R. Costa-jussà and Onur Celebi and Maha Elbayad and Cynthia Gao and Francisco Guzmán and Justine Kao and Ann Lee and Alexandre Mourachko and Juan Pino and Sravya Popuri and Christophe Ropers and Safiyyah Saleem and Holger Schwenk and Paden Tomasello and Changhan Wang and Jeff Wang and Skyler Wang},
      year={2023},
      eprint={2308.11596},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.11596}, 
}

@inproceedings{xtts,
  title     = {{XTTS}: a Massively Multilingual Zero-Shot Text-to-Speech Model},
  author    = {Edresson Casanova and Kelly Davis and Eren Gölge and Görkem Göknar and Iulian Gulea and Logan Hart and Aya Aljafari and Joshua Meyer and Reuben Morais and Samuel Olayemi and Julian Weber},
  year      = {2024},
  booktitle = {Interspeech 2024},
  pages     = {4978--4982},
  doi       = {10.21437/Interspeech.2024-2016},
  issn      = {2958-1796},
}

@INPROCEEDINGS{latent_filling,
  author={Bae, Jae-Sung and Lee, Joun Yeop and Lee, Ji-Hyun and Mun, Seongkyu and Kang, Taehwa and Cho, Hoon-Young and Kim, Chanwoo},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Latent Filling: Latent Space Data Augmentation for Zero-Shot Speech Synthesis}, 
  year={2024},
  volume={},
  number={},
  pages={11166-11170},
  keywords={Training;Degradation;System performance;Training data;Speech enhancement;Signal processing;Data augmentation;Speech synthesis;zero-shot;latent space;data augmentation;cross-lingual},
  doi={10.1109/ICASSP48485.2024.10446098}}

@article{bayseian_optimization_LDA,
  author       = {Onur Boyar and
                  Ichiro Takeuchi},
  title        = {Latent Space Bayesian Optimization With Latent Data Augmentation for
                  Enhanced Exploration},
  journal      = {Neural Comput.},
  volume       = {36},
  number       = {11},
  pages        = {2446--2478},
  year         = {2024},
  url          = {https://doi.org/10.1162/neco\_a\_01708},
  doi          = {10.1162/NECO\_A\_01708},
  timestamp    = {Tue, 26 Nov 2024 17:22:29 +0100},
  biburl       = {https://dblp.org/rec/journals/neco/BoyarT24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{data_aug_via_latent_space,
  author={Liu, Xiaofeng and Zou, Yang and Kong, Lingsheng and Diao, Zhihui and Yan, Junliang and Wang, Jun and Li, Site and Jia, Ping and You, Jane},
  booktitle={2018 24th International Conference on Pattern Recognition (ICPR)}, 
  title={Data Augmentation via Latent Space Interpolation for Image Classification}, 
  year={2018},
  volume={},
  number={},
  pages={728-733},
  keywords={Interpolation;Training;Gallium nitride;Training data;Neural networks;Generative adversarial networks;Image classification;classification;data augmentation;vicinal risk minimization;inter-class sampling},
  doi={10.1109/ICPR.2018.8545506}}

@inproceedings{
cheung2021modals,
title={{MODALS}: Modality-agnostic Automated Data Augmentation in the Latent Space},
author={Tsz-Him Cheung and Dit-Yan Yeung},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=XjYgR6gbCEc}
}

@inproceedings{data_aug_in_feature_space,
  author       = {Terrance DeVries and
                  Graham W. Taylor},
  title        = {Dataset Augmentation in Feature Space},
  booktitle    = {5th International Conference on Learning Representations, {ICLR} 2017,
                  Toulon, France, April 24-26, 2017, Workshop Track Proceedings},
  publisher    = {OpenReview.net},
  year         = {2017},
  url          = {https://openreview.net/forum?id=HyaF53XYx},
  timestamp    = {Thu, 04 Apr 2019 13:20:09 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/DeVriesT17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{a_closer_look_at_feature_space_da,
    title = "A Closer Look At Feature Space Data Augmentation For Few-Shot Intent Classification",
    author = "Kumar, Varun  and
      Glaude, Hadrien  and
      de Lichy, Cyprien  and
      Campbell, Wlliam",
    editor = "Cherry, Colin  and
      Durrett, Greg  and
      Foster, George  and
      Haffari, Reza  and
      Khadivi, Shahram  and
      Peng, Nanyun  and
      Ren, Xiang  and
      Swayamdipta, Swabha",
    booktitle = "Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-6101/",
    doi = "10.18653/v1/D19-6101",
    pages = "1--10",
    abstract = "New conversation topics and functionalities are constantly being added to conversational AI agents like Amazon Alexa and Apple Siri. As data collection and annotation is not scalable and is often costly, only a handful of examples for the new functionalities are available, which results in poor generalization performance. We formulate it as a Few-Shot Integration (FSI) problem where a few examples are used to introduce a new intent. In this paper, we study six feature space data augmentation methods to improve classification performance in FSI setting in combination with both supervised and unsupervised representation learning methods such as BERT. Through realistic experiments on two public conversational datasets, SNIPS, and the Facebook Dialog corpus, we show that data augmentation in feature space provides an effective way to improve intent classification performance in few-shot setting beyond traditional transfer learning approaches. In particular, we show that (a) upsampling in latent space is a competitive baseline for feature space augmentation (b) adding the difference between two examples to a new example is a simple yet effective data augmentation method."
}

@inproceedings{
LeMDA,
title={Learning Multimodal Data Augmentation in Feature Space},
author={Zichang Liu and Zhiqiang Tang and Xingjian Shi and Aston Zhang and Mu Li and Anshumali Shrivastava and Andrew Gordon Wilson},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=6SRDbbvU8s}
}

@article{latentaugment_da_via_guided_manipulation,
  author       = {Lorenzo Tronchin and
                  Minh H. Vu and
                  Paolo Soda and
                  Tommy L{\"{o}}fstedt},
  title        = {LatentAugment: Data Augmentation via Guided Manipulation of GAN's
                  Latent Space},
  journal      = {CoRR},
  volume       = {abs/2307.11375},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2307.11375},
  doi          = {10.48550/ARXIV.2307.11375},
  eprinttype    = {arXiv},
  eprint       = {2307.11375},
  timestamp    = {Wed, 26 Jul 2023 15:34:01 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2307-11375.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{cooperative_training_and_latent_space_da,
  author       = {Chen Chen and
                  Kerstin Hammernik and
                  Cheng Ouyang and
                  Chen Qin and
                  Wenjia Bai and
                  Daniel Rueckert},
  editor       = {Marleen de Bruijne and
                  Philippe C. Cattin and
                  St{\'{e}}phane Cotin and
                  Nicolas Padoy and
                  Stefanie Speidel and
                  Yefeng Zheng and
                  Caroline Essert},
  title        = {Cooperative Training and Latent Space Data Augmentation for Robust
                  Medical Image Segmentation},
  booktitle    = {Medical Image Computing and Computer Assisted Intervention - {MICCAI}
                  2021 - 24th International Conference, Strasbourg, France, September
                  27 - October 1, 2021, Proceedings, Part {III}},
  series       = {Lecture Notes in Computer Science},
  volume       = {12903},
  pages        = {149--159},
  publisher    = {Springer},
  year         = {2021},
  url          = {https://doi.org/10.1007/978-3-030-87199-4\_14},
  doi          = {10.1007/978-3-030-87199-4\_14},
  timestamp    = {Sun, 06 Oct 2024 21:11:15 +0200},
  biburl       = {https://dblp.org/rec/conf/miccai/ChenHOQBR21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{feature_space_augmenation_for_lt_data,
  author       = {Peng Chu and
                  Xiao Bian and
                  Shaopeng Liu and
                  Haibin Ling},
  editor       = {Andrea Vedaldi and
                  Horst Bischof and
                  Thomas Brox and
                  Jan{-}Michael Frahm},
  title        = {Feature Space Augmentation for Long-Tailed Data},
  booktitle    = {Computer Vision - {ECCV} 2020 - 16th European Conference, Glasgow,
                  UK, August 23-28, 2020, Proceedings, Part {XXIX}},
  series       = {Lecture Notes in Computer Science},
  volume       = {12374},
  pages        = {694--710},
  publisher    = {Springer},
  year         = {2020},
  url          = {https://doi.org/10.1007/978-3-030-58526-6\_41},
  doi          = {10.1007/978-3-030-58526-6\_41},
  timestamp    = {Wed, 07 Oct 2020 19:50:12 +0200},
  biburl       = {https://dblp.org/rec/conf/eccv/ChuBLL20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{feature_space_transfer_for_da,
  author       = {Bo Liu and
                  Xudong Wang and
                  Mandar Dixit and
                  Roland Kwitt and
                  Nuno Vasconcelos},
  title        = {Feature Space Transfer for Data Augmentation},
  booktitle    = {2018 {IEEE} Conference on Computer Vision and Pattern Recognition,
                  {CVPR} 2018, Salt Lake City, UT, USA, June 18-22, 2018},
  pages        = {9090--9098},
  publisher    = {Computer Vision Foundation / {IEEE} Computer Society},
  year         = {2018},
  url          = {http://openaccess.thecvf.com/content\_cvpr\_2018/html/Liu\_Feature\_Space\_Transfer\_CVPR\_2018\_paper.html},
  doi          = {10.1109/CVPR.2018.00947},
  timestamp    = {Fri, 24 Mar 2023 00:02:52 +0100},
  biburl       = {https://dblp.org/rec/conf/cvpr/LiuWDKV18.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{pmlr-v202-rangamani23a,
  title = 	 {Feature learning in deep classifiers through Intermediate Neural Collapse},
  author =       {Rangamani, Akshay and Lindegaard, Marius and Galanti, Tomer and Poggio, Tomaso A},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {28729--28745},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/rangamani23a/rangamani23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/rangamani23a.html},
  abstract = 	 {In this paper, we conduct an empirical study of the feature learning process in deep classifiers. Recent research has identified a training phenomenon called Neural Collapse (NC), in which the top-layer feature embeddings of samples from the same class tend to concentrate around their means, and the top layer’s weights align with those features. Our study aims to investigate if these properties extend to intermediate layers. We empirically study the evolution of the covariance and mean of representations across different layers and show that as we move deeper into a trained neural network, the within-class covariance decreases relative to the between-class covariance. Additionally, we find that in the top layers, where the between-class covariance is dominant, the subspace spanned by the class means aligns with the subspace spanned by the most significant singular vector components of the weight matrix in the corresponding layer. Finally, we discuss the relationship between NC and Associative Memories (Willshaw et. al. 1969).}
}









@article{
Prevalence_of_neural_collapse,
author = {Vardan Papyan  and X. Y. Han  and David L. Donoho },
title = {Prevalence of neural collapse during the terminal phase of deep learning training},
journal = {Proceedings of the National Academy of Sciences},
volume = {117},
number = {40},
pages = {24652-24663},
year = {2020},
doi = {10.1073/pnas.2015509117},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2015509117},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2015509117},
abstract = {Modern deep neural networks for image classification have achieved superhuman performance. Yet, the complex details of trained networks have forced most practitioners and researchers to regard them as black boxes with little that could be understood. This paper considers in detail a now-standard training methodology: driving the cross-entropy loss to zero, continuing long after the classification error is already zero. Applying this methodology to an authoritative collection of standard deepnets and datasets, we observe the emergence of a simple and highly symmetric geometry of the deepnet features and of the deepnet classifier, and we document important benefits that the geometry conveys—thereby helping us understand an important component of the modern deep learning training paradigm. Modern practice for training classification deepnets involves a terminal phase of training (TPT), which begins at the epoch where training error first vanishes. During TPT, the training error stays effectively zero, while training loss is pushed toward zero. Direct measurements of TPT, for three prototypical deepnet architectures and across seven canonical classification datasets, expose a pervasive inductive bias we call neural collapse (NC), involving four deeply interconnected phenomena. (NC1) Cross-example within-class variability of last-layer training activations collapses to zero, as the individual activations themselves collapse to their class means. (NC2) The class means collapse to the vertices of a simplex equiangular tight frame (ETF). (NC3) Up to rescaling, the last-layer classifiers collapse to the class means or in other words, to the simplex ETF (i.e., to a self-dual configuration). (NC4) For a given activation, the classifier’s decision collapses to simply choosing whichever class has the closest train class mean (i.e., the nearest class center [NCC] decision rule). The symmetric and very simple geometry induced by the TPT confers important benefits, including better generalization performance, better robustness, and better interpretability.}}

@inproceedings{
cfg,
title={Classifier-Free Diffusion Guidance},
author={Jonathan Ho and Tim Salimans},
booktitle={NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications},
year={2021},
url={https://openreview.net/forum?id=qw8AKxfYbI}
}

@inproceedings{
cfgpp,
title={{CFG}++: Manifold-constrained Classifier Free Guidance for Diffusion Models},
author={Hyungjin Chung and Jeongsol Kim and Geon Yeong Park and Hyelin Nam and Jong Chul Ye},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=E77uvbOTtp}
}

@inproceedings{
ddim,
title={Denoising Diffusion Implicit Models},
author={Jiaming Song and Chenlin Meng and Stefano Ermon},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=St1giarCHLP}
}

@ARTICLE{focal_loss,
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Dollár, Piotr},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Focal Loss for Dense Object Detection}, 
  year={2020},
  volume={42},
  number={2},
  pages={318-327},
  keywords={Detectors;Training;Object detection;Entropy;Proposals;Convolutional neural networks;Feature extraction;Computer vision;object detection;machine learning;convolutional neural networks},
  doi={10.1109/TPAMI.2018.2858826}}

@inproceedings{xlsr,
  title     = {XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale},
  author    = {Arun Babu and Changhan Wang and Andros Tjandra and Kushal Lakhotia and Qiantong Xu and Naman Goyal and Kritika Singh and Patrick {von Platen} and Yatharth Saraf and Juan Pino and Alexei Baevski and Alexis Conneau and Michael Auli},
  year      = {2022},
  booktitle = {Interspeech 2022},
  pages     = {2278--2282},
  doi       = {10.21437/Interspeech.2022-143},
  issn      = {2958-1796},
}

@inproceedings{whisper,
  author       = {Alec Radford and
                  Jong Wook Kim and
                  Tao Xu and
                  Greg Brockman and
                  Christine McLeavey and
                  Ilya Sutskever},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {Robust Speech Recognition via Large-Scale Weak Supervision},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {28492--28518},
  publisher    = {{PMLR}},
  year         = {2023},
  url          = {https://proceedings.mlr.press/v202/radford23a.html},
  timestamp    = {Mon, 28 Aug 2023 17:23:08 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/RadfordKXBMS23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{gender_ref1,
  title     = {Towards Speech Emotion Recognition “in the Wild” Using Aggregated Corpora and Deep Multi-Task Learning},
  author    = {Jaebok Kim and Gwenn Englebienne and Khiet P. Truong and Vanessa Evers},
  year      = {2017},
  booktitle = {Interspeech 2017},
  pages     = {1113--1117},
  doi       = {10.21437/Interspeech.2017-736},
  issn      = {2958-1796},
}

@inproceedings{gender_ref2,
  title     = {Speech Emotion Recognition in the Wild using Multi-task and Adversarial Learning},
  author    = {Jack Parry and Eric DeMattos and Anita Klementiev and Axel Ind and Daniela Morse-Kopp and Georgia Clarke and Dimitri Palaz},
  year      = {2022},
  booktitle = {Interspeech 2022},
  pages     = {1158--1162},
  doi       = {10.21437/Interspeech.2022-10581},
  issn      = {2958-1796},
}

@inproceedings{
adamw,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Bkg6RiCqY7},
}

@inproceedings{interspeech_emotion_challenge,
  title     = {The INTERSPEECH 2009 emotion challenge},
  author    = {Björn Schuller and Stefan Steidl and Anton Batliner},
  year      = {2009},
  booktitle = {Interspeech 2009},
  pages     = {312--315},
  doi       = {10.21437/Interspeech.2009-103},
  issn      = {2958-1796},
}

@inproceedings{ida_cross_speaker_emotion_transfer,
  title     = {Cross-Speaker Emotion Transfer for Low-Resource Text-to-Speech Using Non-Parallel Voice Conversion with Pitch-Shift Data Augmentation},
  author    = {Ryo Terashima and Ryuichi Yamamoto and Eunwoo Song and Yuma Shirahata and Hyun-Wook Yoon and Jae-Min Kim and Kentaro Tachibana},
  year      = {2022},
  booktitle = {Interspeech 2022},
  pages     = {3018--3022},
  doi       = {10.21437/Interspeech.2022-11278},
  issn      = {2958-1796},
}

@INPROCEEDINGS{ida_importantaug,
  author={Trinh, Viet Anh and Salami Kavaki, Hassan and Mandel, Michael I},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Importantaug: A Data Augmentation Agent for Speech}, 
  year={2022},
  volume={},
  number={},
  pages={8592-8596},
  keywords={Vocabulary;Error analysis;Training data;Speech recognition;Signal processing;Robustness;Internet;Data augmentation;importance maps;speech recognition;noise robustness},
  doi={10.1109/ICASSP43922.2022.9747003}}

@inproceedings{specaug,
  title     = {SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition},
  author    = {Daniel S. Park and William Chan and Yu Zhang and Chung-Cheng Chiu and Barret Zoph and Ekin D. Cubuk and Quoc V. Le},
  year      = {2019},
  booktitle = {Interspeech 2019},
  pages     = {2613--2617},
  doi       = {10.21437/Interspeech.2019-2680},
  issn      = {2958-1796},
}

@article{ida_image_traditional1,
  author       = {Connor Shorten and
                  Taghi M. Khoshgoftaar},
  title        = {A survey on Image Data Augmentation for Deep Learning},
  journal      = {J. Big Data},
  volume       = {6},
  pages        = {60},
  year         = {2019},
  url          = {https://doi.org/10.1186/s40537-019-0197-0},
  doi          = {10.1186/S40537-019-0197-0},
  timestamp    = {Tue, 01 Jun 2021 10:00:03 +0200},
  biburl       = {https://dblp.org/rec/journals/jbd/ShortenK19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ida_image_traditional2,
  author       = {Luis Perez and
                  Jason Wang},
  title        = {The Effectiveness of Data Augmentation in Image Classification using
                  Deep Learning},
  journal      = {CoRR},
  volume       = {abs/1712.04621},
  year         = {2017},
  url          = {http://arxiv.org/abs/1712.04621},
  eprinttype    = {arXiv},
  eprint       = {1712.04621},
  timestamp    = {Mon, 13 Aug 2018 16:48:03 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1712-04621.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ida_text_is_all_you_need,
  author       = {Karren D. Yang and
                  Ting{-}Yao Hu and
                  Jen{-}Hao Rick Chang and
                  Hema Swetha Koppula and
                  Oncel Tuzel},
  title        = {Text is all You Need: Personalizing {ASR} Models Using Controllable
                  Speech Synthesis},
  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing
                  {ICASSP} 2023, Rhodes Island, Greece, June 4-10, 2023},
  pages        = {1--5},
  publisher    = {{IEEE}},
  year         = {2023},
  url          = {https://doi.org/10.1109/ICASSP49357.2023.10096971},
  doi          = {10.1109/ICASSP49357.2023.10096971},
  timestamp    = {Sun, 19 Jan 2025 13:18:24 +0100},
  biburl       = {https://dblp.org/rec/conf/icassp/YangHCKT23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ida_speech_enhancement1,
  author       = {Anastasia Kuznetsova and
                  Aswin Sivaraman and
                  Minje Kim},
  title        = {The Potential of Neural Speech Synthesis-Based Data Augmentation for
                  Personalized Speech Enhancement},
  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing
                  {ICASSP} 2023, Rhodes Island, Greece, June 4-10, 2023},
  pages        = {1--5},
  publisher    = {{IEEE}},
  year         = {2023},
  url          = {https://doi.org/10.1109/ICASSP49357.2023.10096601},
  doi          = {10.1109/ICASSP49357.2023.10096601},
  timestamp    = {Sun, 19 Jan 2025 13:18:24 +0100},
  biburl       = {https://dblp.org/rec/conf/icassp/KuznetsovaSK23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{ida_speech_enhamcement_2,
  author       = {Jae{-}Sung Bae and
                  Anastasia Kuznetsova and
                  Dinesh Manocha and
                  John R. Hershey and
                  Trausti T. Kristjansson and
                  Minje Kim},
  title        = {Generative Data Augmentation Challenge: Zero-Shot Speech Synthesis
                  for Personalized Speech Enhancement},
  journal      = {CoRR},
  volume       = {abs/2501.13372},
  year         = {2025},
  url          = {https://doi.org/10.48550/arXiv.2501.13372},
  doi          = {10.48550/ARXIV.2501.13372},
  eprinttype    = {arXiv},
  eprint       = {2501.13372},
  timestamp    = {Fri, 28 Feb 2025 18:55:14 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2501-13372.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ida_keyword_spotting,
  author       = {Hyun Jin Park and
                  Dhruuv Agarwal and
                  Neng Chen and
                  Rentao Sun and
                  Kurt Partridge and
                  Justin Chen and
                  Harry Zhang and
                  Pai Zhu and
                  Jacob Bartel and
                  Kyle Kastner and
                  Gary Wang and
                  Andrew Rosenberg and
                  Quan Wang},
  title        = {Utilizing {TTS} Synthesized Data for Efficient Development of Keyword
                  Spotting Model},
  journal      = {CoRR},
  volume       = {abs/2407.18879},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2407.18879},
  doi          = {10.48550/ARXIV.2407.18879},
  eprinttype    = {arXiv},
  eprint       = {2407.18879},
  timestamp    = {Sat, 24 Aug 2024 12:32:22 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2407-18879.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ida_tts_1,
  author       = {Goeric Huybrechts and
                  Thomas Merritt and
                  Giulia Comini and
                  Bartek Perz and
                  Raahil Shah and
                  Jaime Lorenzo{-}Trueba},
  title        = {Low-Resource Expressive Text-To-Speech Using Data Augmentation},
  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing,
                  {ICASSP} 2021, Toronto, ON, Canada, June 6-11, 2021},
  pages        = {6593--6597},
  publisher    = {{IEEE}},
  year         = {2021},
  url          = {https://doi.org/10.1109/ICASSP39728.2021.9413466},
  doi          = {10.1109/ICASSP39728.2021.9413466},
  timestamp    = {Fri, 09 Jul 2021 13:04:25 +0200},
  biburl       = {https://dblp.org/rec/conf/icassp/HuybrechtsMCPSL21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ida_tts_2,
  author       = {Eunwoo Song and
                  Ryuichi Yamamoto and
                  Ohsung Kwon and
                  Chan{-}Ho Song and
                  Min{-}Jae Hwang and
                  Suhyeon Oh and
                  Hyun{-}Wook Yoon and
                  Jin{-}Seob Kim and
                  Jae{-}Min Kim},
  editor       = {Hanseok Ko and
                  John H. L. Hansen},
  title        = {{TTS-by-TTS 2}: Data-Selective Augmentation for Neural Speech Synthesis
                  Using Ranking Support Vector Machine with Variational Autoencoder},
  booktitle    = {23rd Annual Conference of the International Speech Communication Association,
                  Interspeech 2022, Incheon, Korea, September 18-22, 2022},
  pages        = {1941--1945},
  publisher    = {{ISCA}},
  year         = {2022},
  url          = {https://doi.org/10.21437/Interspeech.2022-10134},
  doi          = {10.21437/INTERSPEECH.2022-10134},
  timestamp    = {Tue, 11 Jun 2024 16:45:43 +0200},
  biburl       = {https://dblp.org/rec/conf/interspeech/SongYKSHOYKK22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{ida_emotion_1,
  author={Bo-Hao, Su and Upadhyay, Shreya G. and Chi-Chun, Lee},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Toward Zero-Shot Speech Emotion Recognition Using LLMs in the Absence of Target Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  keywords={Bridges;Emotion recognition;Data privacy;Large language models;Transfer learning;Buildings;Speech recognition;Signal processing;Speech processing;Synthetic data;LLM;zero-shot;speech emotion recognition},
  doi={10.1109/ICASSP49660.2025.10889305}}

@inproceedings{ida_image_1,
  author       = {Khawar Islam and
                  Muhammad Zaigham Zaheer and
                  Arif Mahmood and
                  Karthik Nandakumar},
  title        = {Diffusemix: Label-Preserving Data Augmentation with Diffusion Models},
  booktitle    = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
                  {CVPR} 2024, Seattle, WA, USA, June 16-22, 2024},
  pages        = {27611--27620},
  publisher    = {{IEEE}},
  year         = {2024},
  url          = {https://doi.org/10.1109/CVPR52733.2024.02608},
  doi          = {10.1109/CVPR52733.2024.02608},
  timestamp    = {Sun, 19 Jan 2025 13:39:05 +0100},
  biburl       = {https://dblp.org/rec/conf/cvpr/IslamZMN24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ida_image_2,
  author       = {Brandon Trabucco and
                  Kyle Doherty and
                  Max Gurinas and
                  Ruslan Salakhutdinov},
  title        = {Effective Data Augmentation With Diffusion Models},
  booktitle    = {The Twelfth International Conference on Learning Representations,
                  {ICLR} 2024, Vienna, Austria, May 7-11, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=ZWzUA9zeAg},
  timestamp    = {Wed, 07 Aug 2024 17:11:53 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/TrabuccoDGS24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ida_image_3,
  author       = {Seonghyun Ban and
                  Heesan Kong and
                  Kee{-}Eung Kim},
  editor       = {Amir Globersons and
                  Lester Mackey and
                  Danielle Belgrave and
                  Angela Fan and
                  Ulrich Paquet and
                  Jakub M. Tomczak and
                  Cheng Zhang},
  title        = {Data Augmentation with Diffusion for Open-Set Semi-Supervised Learning},
  booktitle    = {Advances in Neural Information Processing Systems 38: Annual Conference
                  on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver,
                  BC, Canada, December 10 - 15, 2024},
  year         = {2024},
  url          = {http://papers.nips.cc/paper\_files/paper/2024/hash/777cc2af0ab984e6dc48d168ce7b754f-Abstract-Conference.html},
  timestamp    = {Thu, 13 Feb 2025 16:56:44 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/BanKK24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{on_the_opportunities_and_risks,
  author       = {Rishi Bommasani and
                  Drew A. Hudson and
                  Ehsan Adeli and
                  Russ B. Altman and
                  Simran Arora and
                  Sydney von Arx and
                  Michael S. Bernstein and
                  Jeannette Bohg and
                  Antoine Bosselut and
                  Emma Brunskill and
                  Erik Brynjolfsson and
                  Shyamal Buch and
                  Dallas Card and
                  Rodrigo Castellon and
                  Niladri S. Chatterji and
                  Annie S. Chen and
                  Kathleen Creel and
                  Jared Quincy Davis and
                  Dorottya Demszky and
                  Chris Donahue and
                  Moussa Doumbouya and
                  Esin Durmus and
                  Stefano Ermon and
                  John Etchemendy and
                  Kawin Ethayarajh and
                  Li Fei{-}Fei and
                  Chelsea Finn and
                  Trevor Gale and
                  Lauren E. Gillespie and
                  Karan Goel and
                  Noah D. Goodman and
                  Shelby Grossman and
                  Neel Guha and
                  Tatsunori Hashimoto and
                  Peter Henderson and
                  John Hewitt and
                  Daniel E. Ho and
                  Jenny Hong and
                  Kyle Hsu and
                  Jing Huang and
                  Thomas Icard and
                  Saahil Jain and
                  Dan Jurafsky and
                  Pratyusha Kalluri and
                  Siddharth Karamcheti and
                  Geoff Keeling and
                  Fereshte Khani and
                  Omar Khattab and
                  Pang Wei Koh and
                  Mark S. Krass and
                  Ranjay Krishna and
                  Rohith Kuditipudi and
                  et al.},
  title        = {On the Opportunities and Risks of Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2108.07258},
  year         = {2021},
  url          = {https://arxiv.org/abs/2108.07258},
  eprinttype    = {arXiv},
  eprint       = {2108.07258},
  timestamp    = {Fri, 08 Nov 2024 20:52:57 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2108-07258.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{whisper_ser_1,
  author={Goron, Erik and Asai, Lena and Rut, Elias and Dinov, Martin},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Improving Domain Generalization in Speech Emotion Recognition with Whisper}, 
  year={2024},
  volume={},
  number={},
  pages={11631-11635},
  keywords={Emotion recognition;Explainable AI;Signal processing algorithms;Speech recognition;Signal processing;Transformers;Data models;Speech Emotion Recognition (SER);Domain Generalization;Transformers;Whisper;HuBERT},
  doi={10.1109/ICASSP48485.2024.10446997}}

@inproceedings{whisper_audio_tagging,
  author       = {Yuan Gong and
                  Sameer Khurana and
                  Leonid Karlinsky and
                  James R. Glass},
  editor       = {Naomi Harte and
                  Julie Carson{-}Berndsen and
                  Gareth Jones},
  title        = {Whisper-AT: Noise-Robust Automatic Speech Recognizers are Also Strong
                  General Audio Event Taggers},
  booktitle    = {24th Annual Conference of the International Speech Communication Association,
                  Interspeech 2023, Dublin, Ireland, August 20-24, 2023},
  pages        = {2798--2802},
  publisher    = {{ISCA}},
  year         = {2023},
  url          = {https://doi.org/10.21437/Interspeech.2023-2193},
  doi          = {10.21437/INTERSPEECH.2023-2193},
  timestamp    = {Sun, 06 Oct 2024 21:08:23 +0200},
  biburl       = {https://dblp.org/rec/conf/interspeech/0001KKG23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{clip,
  author       = {Alec Radford and
                  Jong Wook Kim and
                  Chris Hallacy and
                  Aditya Ramesh and
                  Gabriel Goh and
                  Sandhini Agarwal and
                  Girish Sastry and
                  Amanda Askell and
                  Pamela Mishkin and
                  Jack Clark and
                  Gretchen Krueger and
                  Ilya Sutskever},
  editor       = {Marina Meila and
                  Tong Zhang},
  title        = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle    = {Proceedings of the 38th International Conference on Machine Learning,
                  {ICML} 2021, 18-24 July 2021, Virtual Event},
  series       = {Proceedings of Machine Learning Research},
  volume       = {139},
  pages        = {8748--8763},
  publisher    = {{PMLR}},
  year         = {2021},
  url          = {http://proceedings.mlr.press/v139/radford21a.html},
  timestamp    = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/RadfordKHRGASAM21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{clip_vqa,
  author       = {Haoyu Song and
                  Li Dong and
                  Weinan Zhang and
                  Ting Liu and
                  Furu Wei},
  editor       = {Smaranda Muresan and
                  Preslav Nakov and
                  Aline Villavicencio},
  title        = {{CLIP} Models are Few-Shot Learners: Empirical Studies on {VQA} and
                  Visual Entailment},
  booktitle    = {Proceedings of the 60th Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland,
                  May 22-27, 2022},
  pages        = {6088--6100},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.acl-long.421},
  doi          = {10.18653/V1/2022.ACL-LONG.421},
  timestamp    = {Mon, 01 Aug 2022 16:27:41 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/0002000W22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{clip_image_denoising,
  author       = {Jun Cheng and
                  Dong Liang and
                  Shan Tan},
  title        = {Transfer {CLIP} for Generalizable Image Denoising},
  booktitle    = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
                  {CVPR} 2024, Seattle, WA, USA, June 16-22, 2024},
  pages        = {25974--25984},
  publisher    = {{IEEE}},
  year         = {2024},
  url          = {https://doi.org/10.1109/CVPR52733.2024.02454},
  doi          = {10.1109/CVPR52733.2024.02454},
  timestamp    = {Tue, 01 Apr 2025 19:06:26 +0200},
  biburl       = {https://dblp.org/rec/conf/cvpr/ChengLT24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{clip_forensic,
  author       = {Xinjie Cui and
                  Yuezun Li and
                  Ao Luo and
                  Jiaran Zhou and
                  Junyu Dong},
  title        = {Forensics Adapter: Adapting {CLIP} for Generalizable Face Forgery
                  Detection},
  journal      = {CoRR},
  volume       = {abs/2411.19715},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2411.19715},
  doi          = {10.48550/ARXIV.2411.19715},
  eprinttype    = {arXiv},
  eprint       = {2411.19715},
  timestamp    = {Wed, 01 Jan 2025 14:15:41 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2411-19715.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{wav2vec,
  author       = {Alexei Baevski and
                  Yuhao Zhou and
                  Abdelrahman Mohamed and
                  Michael Auli},
  editor       = {Hugo Larochelle and
                  Marc'Aurelio Ranzato and
                  Raia Hadsell and
                  Maria{-}Florina Balcan and
                  Hsuan{-}Tien Lin},
  title        = {wav2vec 2.0: {A} Framework for Self-Supervised Learning of Speech
                  Representations},
  booktitle    = {Advances in Neural Information Processing Systems 33: Annual Conference
                  on Neural Information Processing Systems 2020, NeurIPS 2020, December
                  6-12, 2020, virtual},
  year         = {2020},
  url          = {https://proceedings.neurips.cc/paper/2020/hash/92d1e1eb1cd6f9fba3227870bb6d7f07-Abstract.html},
  timestamp    = {Tue, 19 Jan 2021 15:57:22 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/BaevskiZMA20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423/",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
}

@inproceedings{online_zero_shot_classification_with_clip,
  author       = {Qi Qian and
                  Juhua Hu},
  editor       = {Ales Leonardis and
                  Elisa Ricci and
                  Stefan Roth and
                  Olga Russakovsky and
                  Torsten Sattler and
                  G{\"{u}}l Varol},
  title        = {Online Zero-Shot Classification with {CLIP}},
  booktitle    = {Computer Vision - {ECCV} 2024 - 18th European Conference, Milan, Italy,
                  September 29-October 4, 2024, Proceedings, Part {LXXVII}},
  series       = {Lecture Notes in Computer Science},
  volume       = {15135},
  pages        = {462--477},
  publisher    = {Springer},
  year         = {2024},
  url          = {https://doi.org/10.1007/978-3-031-72980-5\_27},
  doi          = {10.1007/978-3-031-72980-5\_27},
  timestamp    = {Tue, 24 Dec 2024 22:38:50 +0100},
  biburl       = {https://dblp.org/rec/conf/eccv/QianH24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lift,
  author       = {Jiang{-}Xin Shi and
                  Tong Wei and
                  Zhi Zhou and
                  Jie{-}Jing Shao and
                  Xin{-}Yan Han and
                  Yufeng Li},
  title        = {Long-Tail Learning with Foundation Model: Heavy Fine-Tuning Hurts},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=ccSSKTz9LX},
  timestamp    = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/Shi00SH024.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@ARTICLE{The_equalization_loss,
  author={Tan, Jingru and Li, Bo and Lu, Xin and Yao, Yongqiang and Yu, Fengwei and He, Tong and Ouyang, Wanli},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={The Equalization Losses: Gradient-Driven Training for Long-tailed Object Recognition}, 
  year={2023},
  volume={45},
  number={11},
  pages={13876-13892},
  keywords={Training;Task analysis;Tail;Object detection;Object recognition;Visualization;Image classification;Image classification;long-tailed object recognition;object detection;semantic segmentation},
  doi={10.1109/TPAMI.2023.3298433}}

@misc{enhancing_features_in_long_tailed,
      title={Enhancing Features in Long-tailed Data Using Large Vision Model}, 
      author={Pengxiao Han and Changkun Ye and Jinguang Tong and Cuicui Jiang and Jie Hong and Li Fang and Xuesong Li},
      year={2025},
      eprint={2504.10852},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.10852}, 
}

@inproceedings{learning_imbalanced_data_with_vision_transformers,
  author       = {Zhengzhuo Xu and
                  Ruikang Liu and
                  Shuo Yang and
                  Zenghao Chai and
                  Chun Yuan},
  title        = {Learning Imbalanced Data with Vision Transformers},
  booktitle    = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
                  {CVPR} 2023, Vancouver, BC, Canada, June 17-24, 2023},
  pages        = {15793--15803},
  publisher    = {{IEEE}},
  year         = {2023},
  url          = {https://doi.org/10.1109/CVPR52729.2023.01516},
  doi          = {10.1109/CVPR52729.2023.01516},
  timestamp    = {Tue, 29 Aug 2023 15:44:40 +0200},
  biburl       = {https://dblp.org/rec/conf/cvpr/XuLYCY23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DeiT-LT,
  author       = {Harsh Rangwani and
                  Pradipto Mondal and
                  Mayank Mishra and
                  Ashish Ramayee Asokan and
                  R. Venkatesh Babu},
  title        = {DeiT-LT: Distillation Strikes Back for Vision Transformer Training
                  on Long-Tailed Datasets},
  booktitle    = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
                  {CVPR} 2024, Seattle, WA, USA, June 16-22, 2024},
  pages        = {23396--23406},
  publisher    = {{IEEE}},
  year         = {2024},
  url          = {https://doi.org/10.1109/CVPR52733.2024.02208},
  doi          = {10.1109/CVPR52733.2024.02208},
  timestamp    = {Fri, 14 Mar 2025 09:22:51 +0100},
  biburl       = {https://dblp.org/rec/conf/cvpr/RangwaniMMMAB24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
vit,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}

@article{ballad,
  author       = {Teli Ma and
                  Shijie Geng and
                  Mengmeng Wang and
                  Jing Shao and
                  Jiasen Lu and
                  Hongsheng Li and
                  Peng Gao and
                  Yu Qiao},
  title        = {A Simple Long-Tailed Recognition Baseline via Vision-Language Model},
  journal      = {CoRR},
  volume       = {abs/2111.14745},
  year         = {2021},
  url          = {https://arxiv.org/abs/2111.14745},
  eprinttype    = {arXiv},
  eprint       = {2111.14745},
  timestamp    = {Fri, 28 Feb 2025 08:18:20 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2111-14745.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{imagenetlt,
  author       = {Ziwei Liu and
                  Zhongqi Miao and
                  Xiaohang Zhan and
                  Jiayun Wang and
                  Boqing Gong and
                  Stella X. Yu},
  title        = {Large-Scale Long-Tailed Recognition in an Open World},
  booktitle    = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
                  2019, Long Beach, CA, USA, June 16-20, 2019},
  pages        = {2537--2546},
  publisher    = {Computer Vision Foundation / {IEEE}},
  year         = {2019},
  url          = {http://openaccess.thecvf.com/content\_CVPR\_2019/html/Liu\_Large-Scale\_Long-Tailed\_Recognition\_in\_an\_Open\_World\_CVPR\_2019\_paper.html},
  doi          = {10.1109/CVPR.2019.00264},
  timestamp    = {Mon, 30 Aug 2021 17:01:14 +0200},
  biburl       = {https://dblp.org/rec/conf/cvpr/0002MZWGY19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{imagenet_orig,
  author       = {Olga Russakovsky and
                  Jia Deng and
                  Hao Su and
                  Jonathan Krause and
                  Sanjeev Satheesh and
                  Sean Ma and
                  Zhiheng Huang and
                  Andrej Karpathy and
                  Aditya Khosla and
                  Michael S. Bernstein and
                  Alexander C. Berg and
                  Li Fei{-}Fei},
  title        = {ImageNet Large Scale Visual Recognition Challenge},
  journal      = {Int. J. Comput. Vis.},
  volume       = {115},
  number       = {3},
  pages        = {211--252},
  year         = {2015},
  url          = {https://doi.org/10.1007/s11263-015-0816-y},
  doi          = {10.1007/S11263-015-0816-Y},
  timestamp    = {Tue, 10 Jan 2023 08:57:16 +0100},
  biburl       = {https://dblp.org/rec/journals/ijcv/RussakovskyDSKS15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{openai_improved_ddpm,
  author       = {Alexander Quinn Nichol and
                  Prafulla Dhariwal},
  editor       = {Marina Meila and
                  Tong Zhang},
  title        = {Improved Denoising Diffusion Probabilistic Models},
  booktitle    = {Proceedings of the 38th International Conference on Machine Learning,
                  {ICML} 2021, 18-24 July 2021, Virtual Event},
  series       = {Proceedings of Machine Learning Research},
  volume       = {139},
  pages        = {8162--8171},
  publisher    = {{PMLR}},
  year         = {2021},
  url          = {http://proceedings.mlr.press/v139/nichol21a.html},
  timestamp    = {Wed, 25 Aug 2021 17:11:17 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/NicholD21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ldm,
  author       = {Robin Rombach and
                  Andreas Blattmann and
                  Dominik Lorenz and
                  Patrick Esser and
                  Bj{\"{o}}rn Ommer},
  title        = {High-Resolution Image Synthesis with Latent Diffusion Models},
  booktitle    = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition,
                  {CVPR} 2022, New Orleans, LA, USA, June 18-24, 2022},
  pages        = {10674--10685},
  publisher    = {{IEEE}},
  year         = {2022},
  url          = {https://doi.org/10.1109/CVPR52688.2022.01042},
  doi          = {10.1109/CVPR52688.2022.01042},
  timestamp    = {Sun, 19 Jan 2025 13:39:04 +0100},
  biburl       = {https://dblp.org/rec/conf/cvpr/RombachBLEO22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{audio_ldm,
  author       = {Haohe Liu and
                  Zehua Chen and
                  Yi Yuan and
                  Xinhao Mei and
                  Xubo Liu and
                  Danilo P. Mandic and
                  Wenwu Wang and
                  Mark D. Plumbley},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {AudioLDM: Text-to-Audio Generation with Latent Diffusion Models},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {21450--21474},
  publisher    = {{PMLR}},
  year         = {2023},
  url          = {https://proceedings.mlr.press/v202/liu23f.html},
  timestamp    = {Fri, 11 Apr 2025 08:50:31 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/LiuCYMLM0P23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{logit_adjusted_loss,
  author       = {Aditya Krishna Menon and
                  Sadeep Jayasumana and
                  Ankit Singh Rawat and
                  Himanshu Jain and
                  Andreas Veit and
                  Sanjiv Kumar},
  title        = {Long-tail learning via logit adjustment},
  booktitle    = {9th International Conference on Learning Representations, {ICLR} 2021,
                  Virtual Event, Austria, May 3-7, 2021},
  publisher    = {OpenReview.net},
  year         = {2021},
  url          = {https://openreview.net/forum?id=37nvvqkCo5},
  timestamp    = {Wed, 23 Jun 2021 17:36:39 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/MenonJRJVK21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{mixup,
  author       = {Hongyi Zhang and
                  Moustapha Ciss{\'{e}} and
                  Yann N. Dauphin and
                  David Lopez{-}Paz},
  title        = {mixup: Beyond Empirical Risk Minimization},
  booktitle    = {6th International Conference on Learning Representations, {ICLR} 2018,
                  Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher    = {OpenReview.net},
  year         = {2018},
  url          = {https://openreview.net/forum?id=r1Ddp1-Rb},
  timestamp    = {Thu, 25 Jul 2019 14:25:50 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/ZhangCDL18.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{cutmix,
  author       = {Sangdoo Yun and
                  Dongyoon Han and
                  Sanghyuk Chun and
                  Seong Joon Oh and
                  Youngjoon Yoo and
                  Junsuk Choe},
  title        = {CutMix: Regularization Strategy to Train Strong Classifiers With Localizable
                  Features},
  booktitle    = {2019 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
                  2019, Seoul, Korea (South), October 27 - November 2, 2019},
  pages        = {6022--6031},
  publisher    = {{IEEE}},
  year         = {2019},
  url          = {https://doi.org/10.1109/ICCV.2019.00612},
  doi          = {10.1109/ICCV.2019.00612},
  timestamp    = {Sun, 04 Aug 2024 19:36:15 +0200},
  biburl       = {https://dblp.org/rec/conf/iccv/YunHCOYC19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{language_relationship_in_emotion_1,
title = {Factors in the recognition of vocally expressed emotions: A comparison of four languages},
journal = {Journal of Phonetics},
volume = {37},
number = {4},
pages = {417-435},
year = {2009},
issn = {0095-4470},
doi = {https://doi.org/10.1016/j.wocn.2009.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0095447009000448},
author = {Marc D. Pell and Silke Paulmann and Chinar Dara and Areej Alasseri and Sonja A. Kotz},
abstract = {To understand how language influences the vocal communication of emotion, we investigated how discrete emotions are recognized and acoustically differentiated in four language contexts—English, German, Hindi, and Arabic. Vocal expressions of six emotions (anger, disgust, fear, sadness, happiness, pleasant surprise) and neutral expressions were elicited from four native speakers of each language. Each speaker produced pseudo-utterances (“nonsense speech”) which resembled their native language to express each emotion type, and the recordings were judged for their perceived emotional meaning by a group of native listeners in each language condition. Emotion recognition and acoustic patterns were analyzed within and across languages. Although overall recognition rates varied by language, all emotions could be recognized strictly from vocal cues in each language at levels exceeding chance. Anger, sadness, and fear tended to be recognized most accurately irrespective of language. Acoustic and discriminant function analyses highlighted the importance of speaker fundamental frequency (i.e., relative pitch level and variability) for signalling vocal emotions in all languages. Our data emphasize that while emotional communication is governed by display rules and other social variables, vocal expressions of ‘basic’ emotion in speech exhibit modal tendencies in their acoustic and perceptual attributes which are largely unaffected by language or linguistic similarity.}
}

@inproceedings{language_relationship_in_emotion_2,
  title     = {Bridging Emotions Across Languages: Low Rank Adaptation for Multilingual Speech Emotion Recognition},
  author    = {Lucas Goncalves and Donita Robinson and Elizabeth Richerson and Carlos Busso},
  year      = {2024},
  booktitle = {Interspeech 2024},
  pages     = {4688--4692},
  doi       = {10.21437/Interspeech.2024-1226},
  issn      = {2958-1796},
}

@article{clip_adopter,
  author={Peng Gao and Shijie Geng and Renrui Zhang and Teli Ma and Rongyao Fang and Yongfeng Zhang and Hongsheng Li and Yu Qiao},
  title={CLIP-Adapter: Better Vision-Language Models with Feature Adapters},
  year={2024},
  month={February},
  cdate={1706745600000},
  journal={Int. J. Comput. Vis.},
  volume={132},
  number={2},
  pages={581-595},
  url={https://doi.org/10.1007/s11263-023-01891-x}
}

@inproceedings{
hu2022lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@inproceedings{
chen2022adaptformer,
title={AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition},
author={Shoufa Chen and Chongjian GE and Zhan Tong and Jiangliu Wang and Yibing Song and Jue Wang and Ping Luo},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=ATiz_CDA66}
}